export const projects = [
    {
        title: "Building a Six-Figure Portfolio From Age 17",
        summary: "My experience from managing a personal portfolio...",
        description: `
            <i>The younger you are, the more risk tolerance you have as you have more total time to invest.</i> This does not mean to purchase exclusively risky assets at a young age, but rather embrace the process of action-based learning when it is affordable. The purpose of this block is to retain transparency on my personal finances.

            <br /><br />

            My first personal portfolio was seeded as a custodial brokerage account, and gaining access to this fueled my curiosity. Working alongside a financial advisor, 
            we built a diversified mix of individual equities, ETFs, and mutual funds, with a tech-focused edge—stocks like NVIDIA corporation (NVDA), Berkshire Hathaway (BRK-B), and Eli Lilly (LLY) were key holdings. Not only was this a long-term investment in my wealth, but in my knowledge and openness to learning more.

            <br /><br />

            Over time, the portfolio grew significantly with a gain of (>422%) with the number of holdings ranging from 14 to 18, blowing away many standard benchmarks and reaching multiple six figures. While I have made many trades in this time, many of them were not extremely significant to the portfolio's overall form (>10%), and I actively avoided day trading. Therefore, this portfolio demonstrates the power of compounding as well as disciplined investment strategies.

            <br /><br />

            Here are some bits I have learned along the way:

            <br /><br />

            <ul style="margin-left: 20px;">
                <li>Invest in a <i>strong brokerage firm</i> and <i>smart financial advisor</i>. This relationship is needed for making informed decisions and avoiding costly mistakes early on.</li>
                <li><i>Active research and engagement trumps emotion-driven investments</i>, espcially with professional guidance.
                <a href="https://www.youtube.com/watch?v=8SbV1jN12RY" 
                    title="Every Bias Explained in 8 Minutes"
                    style="text-decoration: underline; color: #b0b0b0;"
                        target="_blank" 
                    rel="noopener noreferrer">
                            Here is a quick video</a> which describes cognitive biases that govern our decision making every single day.
                </li>
                <li><i>Your own knowledge is an asset</i> - a capital resource that can be leveraged for real-world outcomes. Specialized knowledge can add value to your work and differentiate you from others. This is exactly why I am focused on my academic route, rather than the investment portfolio itself.</li>
            </ul>

            <br />

            As I pursue deeper research, I am focused on leveraging my knowledge in applied math, GPU programming, and quantitative finance to develop skills that can be used across both academic and real-world challenges.
        `,
        tags: "Informative • Personal Finance • Equities • Investing",
        date: "October 2021 - Today",
        gradient: "radial-gradient(#009edc, #009edc)"
    },
    {
        title: "Hybrid ESN + EnKF for Lorenz-96 State Estimation",
        summary: "A novel approach on state estimation using Echo State Networks and Ensemble Kalman Filtering...",
        description: `
        A supervised capstone research project, being a novel approach on state estimation using knowledge on Hybrid
        ESNs (Echo State Networks) and 
        EnKF (Ensemble Kalman Filtering). 
        We train model on noisy samples of the Multiscale Lorenz 96 system, generated by applying a Gaussian noise on the RK4 solver.
        <br /><br />
        
        The Multi-Scale Lorenz-96 describes atmospheric convection and is widely used in ML research due to its simplicity and ability to capture fast and slow time dynamics. Our data was generated using RK-4 methods on an imperfect L-96 model:
            \\[
                \\frac{dX_{k}}{dt}=X_{k-1}(X_{k+1}-X_{k-2})-X_{k}+F-\\frac{hc}{b}\\sum_{j=1}^{J}Y_{j,k}
            \\]
            \\[
                \\frac{dy_{j,k}}{dt}=-cb \\cdot Y_{j+1,k}(Y_{j+2,k}-Y_{k-1,k})-cY_{j,k}+\\frac{hc}{b}X_{k}

            \\]

            <br />

            After data generation, we applied various samples of Gaussian noise and tested models to see which would output the lowest Normalized Root Mean-Squared Error (NRMSE). The models we tested on were an Imperfect Model, an Imperfect model with an EnKF, an Echo State Network, and an ESN with an EnKF. More work is to be done on implementing a Hybrid-ESN, and one with an EnKF.

            <br /><br />
            More information, literature, and results are visible at 
            <a href="https://github.com/mcvlix/lorenz-96-hybrid-esn/" 
               title="State Estimation of the Multi-Scale Lorenz 96 System Using a Hybrid Echo State Network and Ensemble Kalman Filter"
               style="text-decoration: underline; color: #306eff;"
                target="_blank" 
               rel="noopener noreferrer">
            this Github Repository</a>.

            `,
        tags: "ML Research • Reservoir Computing • PDEs • Scikit-learn",
        date: "April - June 2025",
        gradient: "linear-gradient(to right, #ff3a30, #306eff)"
    },
    {
        title: "Benchmarking a Quantum Linear Systems Algorithm (WCISCC 2025)",
        summary: "Tests on an IBM quantum circuit emulator that got 2nd in an HPC competition...",
        description: `
            In February of 2025, UCSC's Supercomputing Team (Not-So-Slow Slugs) participated in the

            <a href="https://www.winterclassicinvitational.com/" 
               title="2025 Winter Classic Invitational Student Cluster Competition
"
               style="text-decoration: underline; color: #ff6666;"
                target="_blank" 
               rel="noopener noreferrer">
            2025 Winter Cluster Invitational Supercomputing Competition</a> 
             (WCISCC 2025) hosted by Hewlett Packard Enterprise (HPE). The competition involved mentoring, compiling and testing HPC workloads on 5 different sponsored supercomputers, in which we placed 2nd out of 13 teams.
            <br /><br />

            While this was a first experience for me, it ended up being very lucrative. My most notable contribution was to Oak Ridge National Laboratory (ORNL)'s
            <a href="https://github.com/olcf/wciscc2025?tab=readme-ov-file" 
               title="2025 WINTER CLASSIC INVITATIONAL STUDENT CLUSTER COMPETITION ORNL CHALLENGE: “BENCHMARKING A QUANTUM LINEAR SYSTEMS ALGORITHM"
               style="text-decoration: underline; color: #ff6666;"
                target="_blank" 
               rel="noopener noreferrer">
            Quantum Challenge</a>.
            <br /><br />
            The goal of this challenge is to 'perform parametric study of a quantum linear systems algorithm (QLSA) on simulators, emulators, and real devices'. The challenge had 3 parts:
            <br /><br />
            <ul style="margin-left: 20px;">
                <li>A fidelity (accuracy) and UQ test on the QLSA simulator, both testing the number of shots and the size of the tridiagonal Toeplitz matrix problem.</li>
                <li>A backend evaluation, comparing the quasi-probability distribution on the simulator, emulator, and real quantum nodes.</li>
                <li>Solving the Hele-Shaw fluid flow problem on the quantum simulator, and plotting the resulting pressure and velocity profiles. Also including as another fidelity analysis.</li>
            </ul>
            
            <br />
            <a href="https://www.winterclassicinvitational.com/uc-santa-cruz-follow-up-interview/" 
               title="UC Santa Cruz Follow Up Interview"
               style="text-decoration: underline; color: #b0b0b0;"
                target="_blank" 
               rel="noopener noreferrer">
            Here</a> is an interview snippet from the competition, soon after completing this study.
            `,
        tags: "HPC • Competition • Quantum • Uncertainty Quantification",
        date: "February - May 2025",
        gradient: "radial-gradient(#ff6666, #ff6666)"
    },
    {
        title: "Resume Classifier ML Model",
        summary: "Using Natural Language Processing to classify resumes with a corporate dataset...",
        description: `
            A formal ML project with a virtual team of 12 using a CNN (Convolutional Neural Network) to predict the role an applicant fits based on resume text. 
            A real, unbalanced dataset of 363 corporate resumes was uses, and performance was tested with our open-source project.
            Most of the codebase is created with scikit-learn. 
            
            <br /><br />
            The full, open-source project is visible at: 
            <a href="https://github.com/meanderson65/AISV.X400.ClassProject" 
               title="GPU MODE - A GPU reading group and community"
               style="text-decoration: underline; color: #305dff;"
                target="_blank" 
               rel="noopener noreferrer">
            this Github Repository</a>.
        `,
        tags: "Python • Natural Language Processing • Scikit-learn • CNN",
        date: "December 2024",
        gradient: "linear-gradient(to left, #305dff, #5840f5)"
    },
    {
        title: "Inline CUDA w/ PyTorch (WIP)",
        summary: "A tutorial on injecting CUDA into your own PyTorch program...",
        description: `
            Programming in CUDA can be very challenging, and the challenge begins with even running your first program on a local machine. However, there is no need to re-invent the wheel, especially if you have programming experience with PyTorch.<br /><br />
            
            Assuming your machine has a Windows 10/11 operating system, and an NVIDIA GPU To inject CUDA into your own PyTorch program: <br /><br />

            Install Python                                                                      <br />
            Install PyTorch with CUDA support for your GPU      <br />
            Download CUDA Toolkit from NVIDIA Developer (Depending on your GPU)     <br />
            Ensure proper paths exist <br />
            Install Visual Studio 2022 with MSVC v143 and Windows SDK 10+        <br />
            Install ninja compiler       <br />
            Create a Python virtual environment and activate it<br />
            Verify GPU is visible to pytorch<br />
            Define a CUDA Kernel using load_inline\

        `,
        tags: "Informative • Tutorial • CUDA • PyTorch",
        date: "September 2025",
        gradient: "linear-gradient(to left, #76b900, #76b900)"
    },
    {
        title: "What Am I Studying Now?",
        summary: "The textbooks, resources, courses, and projects I am working through...",
        description: `
            With most of my experience being in physical ML research and model testing, I am turning my head to applications in finance and a focus on high-performance computing (HPC). This includes readings such as:
            <br /><br />

            • Programming Massively Parallel Processors - David B. Kirk, Wen-mei W. Hwu          <br /> 
            • Advances in Financial Machine Learning - Marcos López de Prado                     <br />
            • Stochastic Calculus for Finance II: Continuous Time Models - Steven E. Shreve      <br /><br />

            I would also like to draw attention to 
            <a href="https://www.youtube.com/channel/UCJgIbYl6C5no72a0NUAPcTA" 
               title="GPU MODE - A GPU reading group and community"
               style="text-decoration: underline; color: #76b900;"
               target="_blank" 
               rel="noopener noreferrer">
            GPU MODE</a>,
            an online reading group and community concerned with GPU (particularly CUDA) programming. While I have not directly contributed to this community, I am following their lectures as it is a very up-to-date and industry involved community.

        `,
        tags: "Informative • Resources • Books",
        date: "Today",
        gradient: "radial-gradient(#ffffff, #90d5ff)"
    },
    {
        title: "Dini's Surface Visualization",
        summary: `
            More on the animation in the background...
        `,
        description: `
            A JavaScript visualization of a parametric curve known as Dini's surface. 
            This render serves as an exercise to template future projects with the greater goal of visualizing theoretical concepts using OpenGL shading algorithms (GLSL). 
            
            The surface is defined as \\( f(u,v): \\mathbb{R}^2 \\rightarrow \\mathbb{R}^3 \\) with parameters \\(a\\) describing the radius and \\(b\\) describing the vertical scale:
            
            \\[
            x = a \\cos u \\sin v, \\quad 
            y = a \\sin u \\sin v, \\quad 
            z = a \\left( \\cos v + \\ln \\tan \\frac{v}{2} \\right) + b u
            \\]
            
            In this animation, \\(u\\) (upper bound for the surface integral) is time-animated using a sine function and \\(a\\) (radius) is animated similarly. 
            The 'web-like' look exists to portray the discretization of input values, as opposed to creating a smooth and opaque figure. The domain mesh is a simple, 100x100 plane.

            <br /><br />
            The color values of each point on the curve are produced as a function of both location on the base (pre-vertexed) 2-dimensional mesh and time.
        `,
        tags: "Three.js • WebGL • GLSL Shaders",
        date: "June 2024",
        gradient: "linear-gradient(to left, #ff8a00, #e52e71)"
    },
];
